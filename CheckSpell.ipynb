{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "' python based spell checker to find misspelt words and give best matching suggestions'"
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "source": [
    "''' python based spell checker to find misspelt words and give best matching suggestions'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import argparse\n",
    "import difflib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "File = open('/Users/1610043/Documents/Spellcheckrepo/Spell_Check_Using_Python/WordsList.txt', 'r')\n",
    "WordsList = []\n",
    "for line in File:\n",
    " stripped_line = line. strip()\n",
    " WordsList. append(stripped_line)\n",
    "File.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "true\n"
    }
   ],
   "source": [
    "# print(WordsList)\n",
    "if 'and' in WordsList:\n",
    " print(\"true\")\n",
    "# string=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "# module used to build information extraction or natural language understanding systems\n",
    "from scipy import spatial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#python -m spacy download en_core_web_md command to install the spacy model\n",
    "nlp = spacy.load('en_core_web_md')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "This function helps us to exclude the nouns and propn\n"
    }
   ],
   "source": [
    "print(\"This function helps us to exclude the nouns and propn\")\n",
    "def find_isnoun(word):\n",
    "    # Create a Doc object\n",
    "    doc = nlp(word)\n",
    "    for token in doc:\n",
    "     pos = (token.text, token.pos_)\n",
    "    #  print(pos)\n",
    "     if pos[1] is  not \"NOUN\":\n",
    "      return 1\n",
    "     else :\n",
    "      return 0\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "('guitarist', 'NOUN')\n0\n"
    }
   ],
   "source": [
    "print(find_isnoun(\"guitarist\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "('running', 'VERB')\n0\n"
    }
   ],
   "source": [
    "print(find_isnoun(\"running\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "('hameed', 'PROPN')\n0\n"
    }
   ],
   "source": [
    "print(find_isnoun(\"hameed\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_suggestions(words_to_search) :\n",
    "    \n",
    "    words_to_search=words_to_search.split(\" \")\n",
    "    words=[word.strip(string.punctuation) for word in words_to_search]\n",
    "    for word in words:\n",
    "     r=find_isnoun(word)\n",
    "     print(r)\n",
    "     \n",
    "     if word not in WordsList:\n",
    "       suggestedwords=difflib.get_close_matches(word, WordsList)\n",
    "       print(\"(Wrong word -> \"+word+\") (suggested Words->\"+\")\")\n",
    "       print(suggestedwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "1\n1\n(Wrong word -> gett) (suggested Words->)\n['get', 'ghetto', 'getter']\n1\n1\n(Wrong word -> noar) (suggested Words->)\n['oar', 'nor', 'notary']\nNone\n(Wrong word -> ) (suggested Words->)\n[]\n1\n1\n0\n(Wrong word -> guitarist) (suggested Words->)\n['sitarist', 'guitar', 'diarist']\n"
    }
   ],
   "source": [
    "show_suggestions(\"hi gett rete noar , got it guitarist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReplaceSuggestionsFile(filename):\n",
    "    file = open(filename, 'r')\n",
    "    pe = list(file.read().split())\n",
    "    print(pe)\n",
    "    # if(not autoreplace):\n",
    "    r=[word.strip(string.punctuation) for word in pe]\n",
    "    print(r)\n",
    "    \n",
    "\n",
    "\n",
    "    fout = open(\"out4.txt\", \"wt\")\n",
    "\n",
    "# for line in fin:\n",
    "\t#read replace the string and write to output file\n",
    "\t# fout.write(line.replace('pyton', 'python'))\n",
    "#close input and output files\n",
    "# fin.close()\n",
    "    # r=[word.strip(string.punctuation) for word in pe]\n",
    "    data = file.read()\n",
    "    for word in pe:\n",
    "     find_isnoun(word)\n",
    "     if word not in WordsList:\n",
    "      suggestedwords=difflib.get_close_matches(word, WordsList)\n",
    "      print(\"(Wrong word -> \"+word+\") (suggested Words->\"+\")\")\n",
    "      print(suggestedwords)\n",
    "      if(len(suggestedwords)>0):\n",
    "       print(\"replacing\")\n",
    "       \n",
    "       data = data.replace(word, suggestedwords[0])\n",
    "    #    file.read().replace(word,suggestedwords[0])\n",
    "    fout.write(data)\n",
    "    fout.close()\n",
    "    print(data)\n",
    "    # print(fout.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "dfgb\n[]\n"
    }
   ],
   "source": [
    "filename='/Users/1610043/Documents/Spellcheckrepo/Spell_Check_Using_Python/Test.txt'\n",
    "file = open(filename, 'r')\n",
    "print(\"dfgb\")\n",
    "file.read().replace(\"hey\",\"suggestedwords[0]\")\n",
    "print(file.readlines())\n",
    "\n",
    "# reading_file = open(\"sample.txt\", \"r\")\n",
    "\n",
    "new_file_content = \"\"\n",
    "for line in file:\n",
    "  stripped_line = line.strip()\n",
    "  print(stripped_line)\n",
    "  new_line = stripped_line.replace(\"car\", \"new string\")\n",
    "  new_file_content += new_line +\"\\n\"\n",
    "  print(new_file_content)\n",
    "file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "writing_file = open(\"Test.txt\", \"w\")\n",
    "writing_file.write(new_file_content)\n",
    "writing_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "['get de pyton']\n"
    }
   ],
   "source": [
    "filename='Spellchecker/Test.txt'\n",
    "file = open(filename, 'r')\n",
    "print(file.readlines())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "show_suggestions() missing 1 required positional argument: 'words_to_search'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-63-2ebbc6642d50>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# autoreplace=args['replace']\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m   \u001b[0mshow_suggestions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: show_suggestions() missing 1 required positional argument: 'words_to_search'"
     ]
    }
   ],
   "source": [
    "    filename='/Users/1610043/Documents/Spellcheckrepo/Spell_Check_Using_Python/Test.txt'\n",
    "    autoreplace='fe'\n",
    "    # string=args['text']\n",
    "    # autoreplace=args['replace']\n",
    "    if(filename is not None):\n",
    "      ReplaceSuggestionsFile(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[\"hey there wat are you dooing aren't you , there ,\"]\n"
    }
   ],
   "source": [
    "filename='Spellchecker/Test.txt'\n",
    "file = open(filename, 'r')\n",
    "print(file.readlines())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python361064bitfc1fc2b22b7a46af971673e48cf69fec",
   "display_name": "Python 3.6.10 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}